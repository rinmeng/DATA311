# Create binned tenure categories
telco$tenure_bins <- cut(telco$tenure,
breaks = c(0, 12, 24, 36, 48, 60, Inf),
labels = c("0-12", "13-24", "25-36", "37-48", "49-60", "60+"),
right = FALSE,   # Include the lower bound, exclude the upper
include.lowest = TRUE)  # Include the lowest value
ggplot(telco, aes(x = tenure_bins, fill = Churn)) +
geom_bar(position = "fill") +
labs(title = "Churn Rate by tenure Bins", x = "Tenure (Months)", y = "Proportion") +
theme_minimal()
telco$MonthlyCharges_bins <- cut(telco$MonthlyCharges,
breaks = c(0, 20, 40, 60, 80, 100, Inf),
labels = c("0-20", "21-40", "41-60", "61-80", "81-100", "100+"),
right = FALSE,   # Include the lower bound, exclude the upper
include.lowest = TRUE)  # Include the lowest value
ggplot(telco, aes(x = MonthlyCharges_bins, fill = Churn)) +
geom_bar(position = "fill") +
labs(title = "Churn Rate by MonthlyCharges Bins", x = "MonthlyCharges ($)", y = "Proportion") +
theme_minimal()
telco$TotalCharges_bins <- cut(telco$TotalCharges,
breaks = c(0, 800, 1600, 2400, 3200, 4000, 4800, Inf),
labels = c("0-800", "801-1600", "1601-2400", "2401-3200", "3201-4000", "4001-4800", "4800+"),
right = FALSE,   # Include the lower bound, exclude the upper
include.lowest = TRUE)  # Include the lowest value
ggplot(telco, aes(x = TotalCharges_bins, fill = Churn)) +
geom_bar(position = "fill") +
labs(title = "Churn Rate by TotalCharges Bins", x = "TotalCharges ($)", y = "Proportion") +
theme_minimal()
set.seed(51940633)
# First split: 70% training and 30% test
sampleSize <- floor(0.7 * nrow(telco))
set <- sample(seq_len(nrow(telco)), size = sampleSize)
telcoTrain <- telco[set, ]
telcoTest <- telco[-set, ]
paste("telcoTrain has", nrow(telcoTrain), "rows which is", sprintf("%.2f",100 * nrow(telcoTrain)/nrow(telco)), "% of the dataset")
paste("telcoTest has", nrow(telcoTest), "rows which is", sprintf("%.2f",100 * nrow(telcoTest)/nrow(telco)), "% of the dataset")
set.seed(51940633)
telcoTrain.glm <- glm(Churn ~ tenure + MonthlyCharges + TotalCharges, data=telcoTrain, family= binomial)
summary(telcoTrain.glm)
set.seed(51940633)
# Now we use those predictors that is significant
telcoTrain.glm9 <- glm(Churn ~ SeniorCitizen + tenure * Contract +
PaymentMethod + PaperlessBilling +
OnlineSecurity + TechSupport + StreamingMovies +
InternetService + MonthlyCharges + TotalCharges,
data=telcoTrain, family=binomial)
summary(telcoTrain.glm9)
library(caret)
library(dplyr)
set.seed(51940633)
# Define the training control for cross-validation
train_control <- trainControl(method = "cv", number = 10)
# Train KNN model
# Specify a grid of k values (for example, from 1 to 20)
k_values <- data.frame(k = seq(1, 50, by = 1))  # Example k values
knn_model <- train(Churn ~ SeniorCitizen + tenure + Contract +
PaymentMethod + PaperlessBilling +
OnlineSecurity + TechSupport + StreamingMovies +
InternetService + MonthlyCharges + TotalCharges,
data=telcoTrain,
method = "knn",
trControl = train_control,
tuneGrid = k_values)
# Display the results
print(knn_model)
plot(knn_model)
library(caret)
library(dplyr)
set.seed(51940633)
train_control <- trainControl(method = "cv", number = 10)
optimal_k <- data.frame(k = knn_model$bestTune$k)
knn_model_optimal <- train(Churn ~ SeniorCitizen + tenure + Contract +
PaymentMethod + PaperlessBilling +
OnlineSecurity + TechSupport + StreamingMovies +
InternetService + MonthlyCharges + TotalCharges,
data = telcoTrain,
method = "knn",
trControl = train_control,
tuneGrid = optimal_k)
print(knn_model_optimal)
library(MASS)
# Train the LDA model using tenure and TotalCharges as predictors
lda_model <- lda(Churn ~ tenure + TotalCharges, data = telcoTrain)
# Display the LDA model summary
print(lda_model)
# To see the coefficients of linear discriminants
lda_model$scaling
library(MASS)
# Train the QDA model using tenure and TotalCharges as predictors
qda_model <- qda(Churn ~ tenure + TotalCharges, data = telcoTrain)
# Display the LDA model summary
print(qda_model)
# To see the coefficients of linear discriminants
qda_model$scaling
# Exercise 7
logistic_pred_q7 <- predict(telcoTrain.glm, newdata = telcoTest, type = "response")
logistic_pred_class_q7 <- ifelse(logistic_pred_q7 > 0.5, "Yes", "No")
logistic_conf_matrix_q7 <- confusionMatrix(factor(logistic_pred_class_q7), telcoTest$Churn)
print(logistic_conf_matrix_q7$table)
# Exercise 9
logistic_pred_q9 <- predict(telcoTrain.glm9, newdata = telcoTest, type = "response")
logistic_pred_class_q9 <- ifelse(logistic_pred_q9 > 0.5, "Yes", "No")
logistic_conf_matrix_q9 <- confusionMatrix(factor(logistic_pred_class_q9), telcoTest$Churn)
print(logistic_conf_matrix_q9$table)
# Exercise 10
knn_predictions <- predict(knn_model, newdata = telcoTest)
knn_conf_matrix <- confusionMatrix(knn_predictions, telcoTest$Churn)
print(knn_conf_matrix$table)
# Exercise 11
knn_pred_optimal <- predict(knn_model_optimal, newdata = telcoTest)
knn_conf_matrix_optimal <- confusionMatrix(knn_pred_optimal, telcoTest$Churn)
print(knn_conf_matrix_optimal$table)
# Exercise 13
lda_pred <- predict(lda_model, newdata = telcoTest)
lda_conf_matrix <- confusionMatrix(lda_pred$class, telcoTest$Churn)
print(lda_conf_matrix$table)
# Exercise 14
qda_pred <- predict(qda_model, newdata = telcoTest)
qda_conf_matrix <- confusionMatrix(qda_pred$class, telcoTest$Churn)
print(qda_conf_matrix$table)
# Exercise 7
logistic_pred_q7 <- predict(telcoTrain.glm, newdata = telcoTest, type = "response")
logistic_pred_class_q7 <- ifelse(logistic_pred_q7 > 0.5, "Yes", "No")
logistic_conf_matrix_q7 <- confusionMatrix(factor(logistic_pred_class_q7), telcoTest$Churn)
print(logistic_conf_matrix_q7$table)
# Exercise 9
logistic_pred_q9 <- predict(telcoTrain.glm9, newdata = telcoTest, type = "response")
logistic_pred_class_q9 <- ifelse(logistic_pred_q9 > 0.5, "Yes", "No")
logistic_conf_matrix_q9 <- confusionMatrix(factor(logistic_pred_class_q9), telcoTest$Churn)
print(logistic_conf_matrix_q9$table)
# Exercise 10
knn_predictions <- predict(knn_model, newdata = telcoTest)
knn_conf_matrix <- confusionMatrix(knn_predictions, telcoTest$Churn)
print(knn_conf_matrix$table)
# Exercise 11
knn_pred_optimal <- predict(knn_model_optimal, newdata = telcoTest)
knn_conf_matrix_optimal <- confusionMatrix(knn_pred_optimal, telcoTest$Churn)
print(knn_conf_matrix_optimal$table)
# Exercise 13
lda_pred <- predict(lda_model, newdata = telcoTest)
lda_conf_matrix <- confusionMatrix(lda_pred$class, telcoTest$Churn)
print(lda_conf_matrix$table)
# Exercise 14
qda_pred <- predict(qda_model, newdata = telcoTest)
qda_conf_matrix <- confusionMatrix(qda_pred$class, telcoTest$Churn)
print(qda_conf_matrix$table)
qda_conf_matrix$byClass["Recall"]
logistic_conf_matrix_q7$byClass["Recall"]
logistic_conf_matrix_q7$byClass["Sensitivity"]
library(caret)
library(dplyr)
set.seed(51940633)
# Define the training control for cross-validation
train_control <- trainControl(method = "cv", number = 10)
# Train KNN model
# Specify a grid of k values (for example, from 1 to 20)
k_values <- data.frame(k = seq(1, 50, by = 1))  # Example k values
knn_model <- train(Churn ~ SeniorCitizen + tenure + Contract +
PaymentMethod + PaperlessBilling +
OnlineSecurity + TechSupport + StreamingMovies +
InternetService + MonthlyCharges + TotalCharges,
data=telcoTrain,
method = "knn",
trControl = train_control,
tuneGrid = k_values)
# Display the results
print(knn_model$results)
plot(knn_model)
library(boot)
library(caret)
# Function to compute recall
compute_recall <- function(data, indices) {
# Sample the data
boot_sample <- data[indices, ]
# Fit the QDA model to the bootstrapped sample
qda_model_boot <- train(Churn ~ ., data = boot_sample, method = "qda")
# Make predictions
qda_pred_boot <- predict(qda_model_boot, newdata = telcoTest)
# Create confusion matrix
qda_conf_matrix_boot <- confusionMatrix(qda_pred_boot, boot_sample$Churn)
# Return recall
return(qda_conf_matrix_boot$byClass["Recall"])
}
# Generate bootstrap samples and calculate recall
set.seed(123)  # For reproducibility
boot_results <- boot(data = telcoTest, statistic = compute_recall, R = 1000)
library(boot)
library(caret)
sum(is.na(telcoTrain))
sum(is.na(telcoTest))
# Function to compute recall
compute_recall <- function(data, indices) {
# Sample the data
boot_sample <- data[indices, ]
# Fit the QDA model to the bootstrapped sample
qda_model_boot <- train(Churn ~ ., data = boot_sample, method = "qda")
# Make predictions
qda_pred_boot <- predict(qda_model_boot, newdata = telcoTest)
# Create confusion matrix
qda_conf_matrix_boot <- confusionMatrix(qda_pred_boot, boot_sample$Churn)
# Return recall
return(qda_conf_matrix_boot$byClass["Recall"])
}
# Generate bootstrap samples and calculate recall
set.seed(123)  # For reproducibility
boot_results <- boot(data = telcoTest, statistic = compute_recall, R = 1000)
library(boot)
library(caret)
# Function to compute recall
compute_recall <- function(data, indices) {
# Sample the data
boot_sample <- data[indices, ]
# Fit the QDA model to the bootstrapped sample
qda_model_boot <- train(Churn ~ ., data = boot_sample, method = "qda")
# Make predictions
qda_pred_boot <- predict(qda_model_boot, newdata = telcoTest)
# Create confusion matrix
qda_conf_matrix_boot <- confusionMatrix(qda_pred_boot, boot_sample$Churn)
# Return recall
return(qda_conf_matrix_boot$byClass["Recall"])
}
# Generate bootstrap samples and calculate recall
set.seed(123)  # For reproducibility
boot_results <- boot(data = telcoTest, statistic = compute_recall, R = 1000)
table(telcoTrain$Churn)
library(boot)
library(caret)
telco <- read.table(("telcochurn.csv"), header=TRUE, sep = ",")
telco <- na.omit(telco)
# Make sure its factored into levels Yes and No
telco$Churn <- as.factor(telco$Churn)
telco$tenure <- as.numeric(telco$tenure)
telco$gender <- as.factor(telco$gender)
telco$SeniorCitizen <- as.factor(telco$SeniorCitizen)
telco$Partner <- as.factor(telco$Partner)
telco$Dependents <- as.factor(telco$Dependents)
telco$PhoneService <- as.factor(telco$PhoneService)
telco$MultipleLines <- as.factor(telco$MultipleLines)
telco$InternetService <- as.factor(telco$InternetService)
telco$OnlineSecurity <- as.factor(telco$OnlineSecurity)
telco$OnlineBackup <- as.factor(telco$OnlineBackup)
telco$DeviceProtection <- as.factor(telco$DeviceProtection)
telco$TechSupport <- as.factor(telco$TechSupport)
telco$StreamingTV <- as.factor(telco$StreamingTV)
telco$StreamingMovies <- as.factor(telco$StreamingMovies)
telco$Contract <- as.factor(telco$Contract)
telco$PaperlessBilling <- as.factor(telco$PaperlessBilling)
telco$PaymentMethod <- as.factor(telco$PaymentMethod)
telco$MonthlyCharges <- as.numeric(telco$MonthlyCharges)
telco$TotalCharges <- as.numeric(telco$TotalCharges)
str(telco)
library(ggplot2)
ggplot(telco, aes(x = Churn)) +
geom_bar(fill = c("steelblue", "tomato")) +
labs(title = "Customer Churn Frequency",
x = "Churn Status",
y = "Frequency") +
theme_minimal()
churnPlot <- function(predictor) {
ggplot(telco, aes_string(x = predictor, fill = "Churn")) +  # Use aes_string for dynamic x aesthetic
geom_bar(position = "fill") +
labs(title = paste("Churn Rate by", predictor), x = predictor, y = "Proportion") +  # Make title dynamic
theme_minimal()
}
# Identify categorical predictors
predictors <- colnames(telco)
exclude_columns <- c("customerID","Churn", "MonthlyCharges", "TotalCharges","tenure","tenure_bins","TotalCharges_bins","MonthlyCharges_bin")
predictors <- predictors[!predictors %in% exclude_columns]
for (predictor in predictors) {
print(churnPlot(predictor))
}
# Create binned tenure categories
telco$tenure_bins <- cut(telco$tenure,
breaks = c(0, 12, 24, 36, 48, 60, Inf),
labels = c("0-12", "13-24", "25-36", "37-48", "49-60", "60+"),
right = FALSE,   # Include the lower bound, exclude the upper
include.lowest = TRUE)  # Include the lowest value
ggplot(telco, aes(x = tenure_bins, fill = Churn)) +
geom_bar(position = "fill") +
labs(title = "Churn Rate by tenure Bins", x = "Tenure (Months)", y = "Proportion") +
theme_minimal()
telco$MonthlyCharges_bins <- cut(telco$MonthlyCharges,
breaks = c(0, 20, 40, 60, 80, 100, Inf),
labels = c("0-20", "21-40", "41-60", "61-80", "81-100", "100+"),
right = FALSE,   # Include the lower bound, exclude the upper
include.lowest = TRUE)  # Include the lowest value
ggplot(telco, aes(x = MonthlyCharges_bins, fill = Churn)) +
geom_bar(position = "fill") +
labs(title = "Churn Rate by MonthlyCharges Bins", x = "MonthlyCharges ($)", y = "Proportion") +
theme_minimal()
telco$TotalCharges_bins <- cut(telco$TotalCharges,
breaks = c(0, 800, 1600, 2400, 3200, 4000, 4800, Inf),
labels = c("0-800", "801-1600", "1601-2400", "2401-3200", "3201-4000", "4001-4800", "4800+"),
right = FALSE,   # Include the lower bound, exclude the upper
include.lowest = TRUE)  # Include the lowest value
ggplot(telco, aes(x = TotalCharges_bins, fill = Churn)) +
geom_bar(position = "fill") +
labs(title = "Churn Rate by TotalCharges Bins", x = "TotalCharges ($)", y = "Proportion") +
theme_minimal()
set.seed(51940633)
# First split: 70% training and 30% test
sampleSize <- floor(0.7 * nrow(telco))
set <- sample(seq_len(nrow(telco)), size = sampleSize)
telcoTrain <- telco[set, ]
telcoTest <- telco[-set, ]
paste("telcoTrain has", nrow(telcoTrain), "rows which is", sprintf("%.2f",100 * nrow(telcoTrain)/nrow(telco)), "% of the dataset")
paste("telcoTest has", nrow(telcoTest), "rows which is", sprintf("%.2f",100 * nrow(telcoTest)/nrow(telco)), "% of the dataset")
set.seed(51940633)
telcoTrain.glm <- glm(Churn ~ tenure + MonthlyCharges + TotalCharges, data=telcoTrain, family= binomial)
summary(telcoTrain.glm)
set.seed(51940633)
# Now we use those predictors that is significant
telcoTrain.glm9 <- glm(Churn ~ SeniorCitizen + tenure * Contract +
PaymentMethod + PaperlessBilling +
OnlineSecurity + TechSupport + StreamingMovies +
InternetService + MonthlyCharges + TotalCharges,
data=telcoTrain, family=binomial)
summary(telcoTrain.glm9)
library(caret)
library(dplyr)
set.seed(51940633)
# Define the training control for cross-validation
train_control <- trainControl(method = "cv", number = 10)
# Train KNN model
# Specify a grid of k values (for example, from 1 to 20)
k_values <- data.frame(k = seq(1, 50, by = 1))  # Example k values
knn_model <- train(Churn ~ SeniorCitizen + tenure + Contract +
PaymentMethod + PaperlessBilling +
OnlineSecurity + TechSupport + StreamingMovies +
InternetService + MonthlyCharges + TotalCharges,
data=telcoTrain,
method = "knn",
trControl = train_control,
tuneGrid = k_values)
# Display the results
print(knn_model)
plot(knn_model)
library(caret)
library(dplyr)
set.seed(51940633)
train_control <- trainControl(method = "cv", number = 10)
optimal_k <- data.frame(k = knn_model$bestTune$k)
knn_model_optimal <- train(Churn ~ SeniorCitizen + tenure + Contract +
PaymentMethod + PaperlessBilling +
OnlineSecurity + TechSupport + StreamingMovies +
InternetService + MonthlyCharges + TotalCharges,
data = telcoTrain,
method = "knn",
trControl = train_control,
tuneGrid = optimal_k)
print(knn_model_optimal)
library(MASS)
lda_model <- lda(Churn ~ tenure + TotalCharges, data = telcoTrain)
print(lda_model)
library(MASS)
qda_model <- qda(Churn ~ tenure + TotalCharges, data = telcoTrain)
print(qda_model)
# Exercise 7
logistic_pred_q7 <- predict(telcoTrain.glm, newdata = telcoTest, type = "response")
logistic_pred_class_q7 <- ifelse(logistic_pred_q7 > 0.5, "Yes", "No")
logistic_conf_matrix_q7 <- confusionMatrix(factor(logistic_pred_class_q7), telcoTest$Churn)
print(logistic_conf_matrix_q7$table)
# Exercise 9
logistic_pred_q9 <- predict(telcoTrain.glm9, newdata = telcoTest, type = "response")
logistic_pred_class_q9 <- ifelse(logistic_pred_q9 > 0.5, "Yes", "No")
logistic_conf_matrix_q9 <- confusionMatrix(factor(logistic_pred_class_q9), telcoTest$Churn)
print(logistic_conf_matrix_q9$table)
# Exercise 10
knn_predictions <- predict(knn_model, newdata = telcoTest)
knn_conf_matrix <- confusionMatrix(knn_predictions, telcoTest$Churn)
print(knn_conf_matrix$table)
# Exercise 11
knn_pred_optimal <- predict(knn_model_optimal, newdata = telcoTest)
knn_conf_matrix_optimal <- confusionMatrix(knn_pred_optimal, telcoTest$Churn)
print(knn_conf_matrix_optimal$table)
# Exercise 13
lda_pred <- predict(lda_model, newdata = telcoTest)
lda_conf_matrix <- confusionMatrix(lda_pred$class, telcoTest$Churn)
print(lda_conf_matrix$table)
# Exercise 14
qda_pred <- predict(qda_model, newdata = telcoTest)
qda_conf_matrix <- confusionMatrix(qda_pred$class, telcoTest$Churn)
print(qda_conf_matrix$table)
library(boot)
library(caret)
# Function to compute recall
compute_recall <- function(data, indices) {
# Sample the data
boot_sample <- data[indices, ]
# Fit the QDA model to the bootstrapped sample
qda_model_boot <- train(Churn ~ ., data = boot_sample, method = "qda")
# Make predictions
qda_pred_boot <- predict(qda_model_boot, newdata = telcoTest)
# Create confusion matrix
qda_conf_matrix_boot <- confusionMatrix(qda_pred_boot, boot_sample$Churn)
# Return recall
return(qda_conf_matrix_boot$byClass["Recall"])
}
# Generate bootstrap samples and calculate recall
set.seed(123)  # For reproducibility
boot_results <- boot(data = telcoTest, statistic = compute_recall, R = 1000)
# Assuming qda_model and telcoTest are already defined
# Number of bootstrap samples
n_bootstrap <- 1000
recalls <- numeric(n_bootstrap)
# Function to calculate recall
get_recall <- function(conf_matrix) {
recall <- conf_matrix$byClass['Recall']
return(recall)
}
set.seed(123)  # For reproducibility
for (i in 1:n_bootstrap) {
# Resample with replacement
telcoTest_bootstrap <- telcoTest[sample(nrow(telcoTest), replace = TRUE), ]
# Make predictions on the bootstrap sample
qda_pred_bootstrap <- predict(qda_model, newdata = telcoTest_bootstrap)
# Get confusion matrix
conf_matrix_bootstrap <- confusionMatrix(qda_pred_bootstrap$class, telcoTest_bootstrap$Churn)
# Store recall
recalls[i] <- get_recall(conf_matrix_bootstrap)
}
# Calculate standard deviation of recall
recall_sd <- sd(recalls)
print(paste("Standard Deviation of Recall:", recall_sd))
# Construct a 95% confidence interval
ci_lower <- quantile(recalls, 0.025)
ci_upper <- quantile(recalls, 0.975)
print(paste("95% Confidence Interval for Recall:", ci_lower, "-", ci_upper))
# Assuming qda_model and telcoTest are already defined
# Number of bootstrap samples
n_bootstrap <- 1000
recalls <- numeric(n_bootstrap)
# Function to calculate recall
get_recall <- function(conf_matrix) {
recall <- conf_matrix$byClass['Recall']
return(recall)
}
set.seed(51940633)  # For reproducibility
for (i in 1:n_bootstrap) {
# Resample with replacement
telcoTest_bootstrap <- telcoTest[sample(nrow(telcoTest), replace = TRUE), ]
# Make predictions on the bootstrap sample
qda_pred_bootstrap <- predict(qda_model, newdata = telcoTest_bootstrap)
# Get confusion matrix
conf_matrix_bootstrap <- confusionMatrix(qda_pred_bootstrap$class, telcoTest_bootstrap$Churn)
# Store recall
recalls[i] <- get_recall(conf_matrix_bootstrap)
}
# Calculate standard deviation of recall
recall_sd <- sd(recalls)
print(paste("Standard Deviation of Recall:", recall_sd))
# Construct a 95% confidence interval
ci_lower <- quantile(recalls, 0.025)
ci_upper <- quantile(recalls, 0.975)
print(paste("95% Confidence Interval for Recall:", ci_lower, "-", ci_upper))
conf_matrix$byClass['Recall']
qda_pred$byClass['Recall']
qda_pred_bootstrap$byClass['Recall']
# Load necessary libraries
library(MASS)
library(caret)
library(boot)
# Define a function to compute recall
compute_recall <- function(data, indices) {
# Sample the data
resampled_data <- data[indices, ]
# Fit QDA model
qda_model <- qda(Churn ~ ., data = resampled_data)
# Predict on the test set
qda_pred <- predict(qda_model, newdata = telcoTest)
# Compute confusion matrix
conf_matrix <- confusionMatrix(qda_pred$class, telcoTest$Churn)
# Extract recall
recall <- conf_matrix$byClass['Recall']
return(recall)
}
# Apply bootstrapping (e.g., 1000 resamples)
set.seed(123)  # For reproducibility
results <- boot(data = telcoTrain, statistic = compute_recall, R = 1000)
library(caret)
library(dplyr)
set.seed(51940633)
# Define the training control for cross-validation
control_10fold <- trainControl(method = "cv", number = 10)
# Train KNN model
# Specify a grid of k values (for example, from 1 to 20)
k_values <- data.frame(k = seq(1, 50, by = 1))  # Example k values
knn_model <- train(Churn ~ SeniorCitizen + tenure + Contract +
PaymentMethod + PaperlessBilling +
OnlineSecurity + TechSupport + StreamingMovies +
InternetService + MonthlyCharges + TotalCharges,
data=telcoTrain,
method = "knn",
trControl = control_10fold,
tuneGrid = k_values)
# Display the results
print(knn_model)
plot(knn_model)
library(caret)
library(dplyr)
set.seed(51940633)
control_10fold <- trainControl(method = "cv", number = 10)
optimal_k <- data.frame(k = knn_model$bestTune$k)
knn_model_optimal <- train(Churn ~ SeniorCitizen + tenure + Contract +
PaymentMethod + PaperlessBilling +
OnlineSecurity + TechSupport + StreamingMovies +
InternetService + MonthlyCharges + TotalCharges,
data = telcoTrain,
method = "knn",
trControl = control_10fold,
tuneGrid = optimal_k)
print(knn_model_optimal)
